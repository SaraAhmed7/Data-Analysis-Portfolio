import requests
from bs4 import BeautifulSoup
import pandas as pd

base_url = "http://books.toscrape.com/catalogue/"
start_url = "http://books.toscrape.com/catalogue/page-1.html"

data = []

url = start_url
while True:
    response = requests.get(url)
    response.raise_for_status() # Raise an exception for bad status codes
    soup = BeautifulSoup(response.content, "lxml")

    # Get all books on the page
    books = soup.find_all("article", class_="product_pod")
    for book in books:
      title = book.h3.a['title']
      price = book.find("p", {"class": "price_color"}).text
      availability = book.find("p", class_="instock availability").text.strip()
      ratingStars = book.find("p")["class"][1]
      data.append([title, price, availability, ratingStars]) # Append book data to the list

    next_btn = soup.find("li", class_="next")
    if next_btn:
        next_page = next_btn.a["href"]
        url = base_url + next_page
    else:
        break

df = pd.DataFrame(data, columns=["title", "price", "availability", "ratingStars"])
df.to_csv("books.csv", index=False)
